{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a SVC classifier by your own pics.\n",
    "用自己家人的照片訓練一個classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Functions for building the face recognition network.\n",
    "\n",
    "   facenet.py\n",
    "   \n",
    "\"\"\"\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import imageio                        # scipy.misc.imsave has been deprecated in newer Scipy versions.\n",
    "                                      # try this if you got error on 'scipy.misc' has no attribute 'imread'\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "from tensorflow.python.training import training\n",
    "import random\n",
    "import re\n",
    "from tensorflow.python.platform import gfile\n",
    "import math\n",
    "from six import iteritems\n",
    "\n",
    "\n",
    "def get_dataset(path, has_class_directories=True):\n",
    "    dataset = []\n",
    "    path_exp = os.path.expanduser(path)\n",
    "    classes = [path for path in os.listdir(path_exp) \\\n",
    "                    if os.path.isdir(os.path.join(path_exp, path))]\n",
    "    classes.sort()\n",
    "    nrof_classes = len(classes)\n",
    "    for i in range(nrof_classes):\n",
    "        class_name = classes[i]\n",
    "        facedir = os.path.join(path_exp, class_name)\n",
    "        image_paths = get_image_paths(facedir)\n",
    "        dataset.append(ImageClass(class_name, image_paths))\n",
    "  \n",
    "    return dataset\n",
    "\n",
    "def get_image_paths(facedir):\n",
    "    image_paths = []\n",
    "    if os.path.isdir(facedir):\n",
    "        images = os.listdir(facedir)\n",
    "        image_paths = [os.path.join(facedir,img) for img in images]\n",
    "    return image_paths\n",
    "\n",
    "def get_image_paths_and_labels(dataset):\n",
    "    image_paths_flat = []\n",
    "    labels_flat = []\n",
    "    for i in range(len(dataset)):\n",
    "        image_paths_flat += dataset[i].image_paths\n",
    "        labels_flat += [i] * len(dataset[i].image_paths)\n",
    "    return image_paths_flat, labels_flat\n",
    "\n",
    "def load_model(model, input_map=None):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    src_path = os.path.join(os.getcwd(), model) # download pre-trained facenet ResNet model, put under the \"models\" folder\n",
    "    model_exp = os.path.expanduser(src_path)\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, input_map=input_map, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "        \n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y  \n",
    "        \n",
    "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n",
    "    nrof_samples = len(image_paths)\n",
    "    images = np.zeros((nrof_samples, image_size, image_size, 3))\n",
    "    for i in range(nrof_samples):\n",
    "        #img = misc.imread(image_paths[i])\n",
    "        img = imageio.imread(image_paths[i])         # try this if you got error on 'scipy.misc' has no attribute 'imread'\n",
    "        if img.ndim == 2:\n",
    "            img = to_rgb(img)\n",
    "        if do_prewhiten:\n",
    "            img = prewhiten(img)\n",
    "        img = crop(img, do_random_crop, image_size)\n",
    "        img = flip(img, do_random_flip)\n",
    "        images[i,:,:,:] = img\n",
    "    return images\n",
    "\n",
    "def crop(image, random_crop, image_size):\n",
    "    if image.shape[1]>image_size:\n",
    "        sz1 = int(image.shape[1]//2)\n",
    "        sz2 = int(image_size//2)\n",
    "        if random_crop:\n",
    "            diff = sz1-sz2\n",
    "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n",
    "        else:\n",
    "            (h, v) = (0,0)\n",
    "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n",
    "    return image\n",
    "\n",
    "def flip(image, random_flip):\n",
    "    if random_flip and np.random.choice([True, False]):\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "class ImageClass():\n",
    "    \"Stores the paths to images for a given class\"\n",
    "    def __init__(self, name, image_paths):\n",
    "        self.name = name\n",
    "        self.image_paths = image_paths\n",
    "  \n",
    "    def __str__(self):\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        return meta_file, ckpt_file\n",
    "\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mode', type=str, #choices=['TRAIN', 'CLASSIFY'],\n",
    "    help='Indicates if a new classifier should be trained or a classification ' + \n",
    "    'model should be used for classification', default='TRAIN')  # default could be either 'TRAIN' or 'CLASSIFY' , choices=['TRAIN', 'CLASSIFY']\n",
    "parser.add_argument('--data_dir', type=str, default=r\"input_dir\",\n",
    "    help='Path to the data directory containing aligned LFW face patches.')\n",
    "parser.add_argument('--model', type=str, default=r\"models\",\n",
    "    help='Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file')\n",
    "parser.add_argument('--classifier_filename', default=\"my_classifier.pkl\",\n",
    "    help='Classifier model file name as a pickle (.pkl) file. ' + \n",
    "    'For training this is the output and for classification this is an input.')\n",
    "parser.add_argument('--use_split_dataset', \n",
    "    help='Indicates that the dataset specified by data_dir should be split into a training and test set. ' +  \n",
    "    'Otherwise a separate test set can be specified using the test_data_dir option.', action='store_true')\n",
    "parser.add_argument('--test_data_dir', type=str,  default=r\"input_dir\",\n",
    "    help='Path to the test data directory containing aligned images used for testing.')\n",
    "parser.add_argument('--batch_size', type=int,\n",
    "    help='Number of images to process in a batch.', default=90)\n",
    "parser.add_argument('--image_size', type=int,\n",
    "    help='Image size (height, width) in pixels.', default=160)\n",
    "parser.add_argument('--seed', type=int,\n",
    "    help='Random seed.', default=666)\n",
    "parser.add_argument('--min_nrof_images_per_class', type=int,\n",
    "    help='Only include classes with at least this number of images in the dataset', default=25)\n",
    "parser.add_argument('--nrof_train_images_per_class', type=int,\n",
    "    help='Use this number of images from each class for training and the rest for testing', default=15)\n",
    "\n",
    "args = parser.parse_args(args=[\"--mode\", \"TRAIN\", \"--data_dir\", \"input_dir\", \"--model\", \"models\", \"--classifier_filename\", \"my_classifier.pkl\",\n",
    "                               \"--use_split_dataset\", \"--test_data_dir\", r\"input_dir\", \"--batch_size\", \"90\", \"--image_size\", \"160\",\n",
    "                               \"--seed\", \"666\", \"--min_nrof_images_per_class\", \"25\", \"--nrof_train_images_per_class\", \"15\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:54: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:54: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:54: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-3-b587b2e85074>:54: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"An example of how to use your own dataset to train a classifier that recognizes people.\n",
    "\n",
    "   classifier.py\n",
    "\"\"\"\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "#import facenet\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def main(args):\n",
    "  \n",
    "    with tf.Graph().as_default():\n",
    "      \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            np.random.seed(seed=args.seed)\n",
    "            \n",
    "            if args.use_split_dataset:\n",
    "                #dataset_tmp = facenet.get_dataset(args.data_dir)\n",
    "                dataset_tmp = get_dataset(args.data_dir)\n",
    "                train_set, test_set = split_dataset(dataset_tmp, args.min_nrof_images_per_class, args.nrof_train_images_per_class)\n",
    "                if (args.mode=='TRAIN'):\n",
    "                    dataset = train_set         # train mode, load train_set\n",
    "                elif (args.mode=='CLASSIFY'):\n",
    "                    dataset = test_set          # classify mode, load test_set\n",
    "            else:\n",
    "                #dataset = facenet.get_dataset(args.data_dir)\n",
    "                dataset = get_dataset(args.data_dir)\n",
    "\n",
    "            # Check that there are at least one training image per class\n",
    "            for cls in dataset:\n",
    "                assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')            \n",
    "\n",
    "                 \n",
    "            #paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "            paths, labels = get_image_paths_and_labels(dataset)\n",
    "            \n",
    "            print('Number of classes: %d' % len(dataset))\n",
    "            print('Number of images: %d' % len(paths))\n",
    "            \n",
    "            # Load the model\n",
    "            print('Loading feature extraction model')\n",
    "            #facenet.load_model(args.model)\n",
    "            load_model(args.model)             # load facenet Inception ResNet v1 model\n",
    "            \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "            \n",
    "            # Run forward pass to calculate embeddings\n",
    "            print('Calculating features for images')\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / args.batch_size))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            for i in range(nrof_batches_per_epoch):\n",
    "                start_index = i*args.batch_size\n",
    "                end_index = min((i+1)*args.batch_size, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                #images = facenet.load_data(paths_batch, False, False, args.image_size)\n",
    "                images = load_data(paths_batch, False, False, args.image_size)\n",
    "                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            \n",
    "            src_path = os.path.join(os.getcwd(), args.model)\n",
    "            classifier_filename_exp = os.path.join(src_path, args.classifier_filename) # define .pkl file path\n",
    "\n",
    "            if (args.mode=='TRAIN'):                                # train mode\n",
    "                # Train classifier\n",
    "                print('Training classifier')\n",
    "                model = SVC(kernel='linear', probability=True)     # train classifier with SVC\n",
    "                model.fit(emb_array, labels)                        # labels assigned by dataset folders priority, 0, 1, 2 ...\n",
    "            \n",
    "                # Create a list of class names\n",
    "                class_names = [cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "                # Saving classifier model\n",
    "                with open(classifier_filename_exp, 'wb') as outfile:\n",
    "                    pickle.dump((model, class_names), outfile)      # output SVC weights as a pkl file\n",
    "                print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "                \n",
    "            elif (args.mode=='CLASSIFY'):                          # classify mode\n",
    "                # Classify images\n",
    "                print('Testing classifier')\n",
    "                with open(classifier_filename_exp, 'rb') as infile:\n",
    "                    (model, class_names) = pickle.load(infile)     # load SVC model weight\n",
    "\n",
    "                print('Loaded classifier model from file \"%s\"' % classifier_filename_exp)\n",
    "\n",
    "                predictions = model.predict_proba(emb_array)         # predict by embedding vector (softmax result)\n",
    "                best_class_indices = np.argmax(predictions, axis=1)  # get the index of best score from softmax result\n",
    "                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices] # [item_num, best_class_indices]\n",
    "                \n",
    "                for i in range(len(best_class_indices)):\n",
    "                    print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n",
    "                    \n",
    "                accuracy = np.mean(np.equal(best_class_indices, labels))\n",
    "                print('Accuracy: %.3f' % accuracy)\n",
    "                \n",
    "            \n",
    "def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for cls in dataset:\n",
    "        paths = cls.image_paths\n",
    "        # Remove classes with less than min_nrof_images_per_class\n",
    "        if len(paths)>=min_nrof_images_per_class:\n",
    "            np.random.shuffle(paths)\n",
    "            #train_set.append(facenet.ImageClass(cls.name, paths[:nrof_train_images_per_class]))\n",
    "            #test_set.append(facenet.ImageClass(cls.name, paths[nrof_train_images_per_class:]))\n",
    "            train_set.append(ImageClass(cls.name, paths[:nrof_train_images_per_class]))\n",
    "            test_set.append(ImageClass(cls.name, paths[nrof_train_images_per_class:]))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset input directory before you run\n",
    "<br>1. Need to creat a \"input_dir\" folder as a Input path 建立 \"input_dir\" 資料夾, 把要輸入的照片(160x160)放裡面\n",
    "<br>2. Need to creat a \"model\" folder, put the download model & weight(<a href=\"https://drive.google.com/file/d/1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-/view\">20180402-114759</a>) here, 建立 \"model\" 資料夾, 把下載的模型參數放這\n",
    "<br>We will get a classifier model(.pkl), will also output in the model directory, 等下產出的classifier模型參數(.pkl)也會在這出現\n",
    "<br><p style=\"text-align:left;\"><img src=\"images/dir_struc.png\"  style=\"width:861px;height:496px;\" align=\"left\">\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "<br>3-1. Train or Classify, when you want to train a new classifier, define the args.modle = TRAIN, in the above cell\n",
    "<br>   args = parser.parse_args(args=[\"--mode\", <b style=\"font-size:100%;\">\"TRAIN\", </b>...\n",
    "<br>   訓練時須將上方code改成 \"--mode\"部分的default值設定為 TRAIN\n",
    "<br>3-2. Train or Classify, when you want to test the classifier, define the args.modle = CLASSIFY, in the above cell\n",
    "<br>   args = parser.parse_args(args=[\"--mode\", <b style=\"font-size:100%;\">\"CLASSIFY\", </b>...\n",
    "<br>   訓練完成後須將上方code改成 \"--mode\"部分的default值設定為 CLASSIFY, 進行TEST\n",
    "\n",
    "<br>4-1. set your default value for min_nrof_images_per_class, in the above cell\n",
    "<br>   args = parser.parse_args(args=[,<b style=\"font-size:100%;\">\"--min_nrof_images_per_class\", \"25\"</b>,...\n",
    "<br>   input_dir中, 相片少於這個數目的類別, 不會輸入\n",
    "<br>4-2. set your default value for nrof_train_images_per_class, in the above cell\n",
    "<br>   args = parser.parse_args(args=[,<b style=\"font-size:100%;\">\"--nrof_train_images_per_class\", \"15\"</b>,...\n",
    "<br>   input_dir中, 每個輸入SVC classifier的類別, 會用其中一部分作為training set使用, 剩餘的作為test set使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4\n",
      "Number of images: 60\n",
      "Loading feature extraction model\n",
      "Model directory: C:\\Users\\user\\face_recog\\DGEs\\facenet_upload\\step3_classifier\\models\n",
      "Metagraph file: model-20180402-114759.meta\n",
      "Checkpoint file: model-20180402-114759.ckpt-275\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\py37_tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\user\\face_recog\\DGEs\\facenet_upload\\step3_classifier\\models\\model-20180402-114759.ckpt-275\n",
      "Calculating features for images\n",
      "Training classifier\n",
      "Saved classifier model to file \"C:\\Users\\user\\face_recog\\DGEs\\facenet_upload\\step3_classifier\\models\\my_classifier.pkl\"\n"
     ]
    }
   ],
   "source": [
    "main(args) # initiate main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
